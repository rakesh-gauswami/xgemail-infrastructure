#!/usr/bin/env python
# vim: autoindent expandtab filetype=python shiftwidth=4 softtabstop=4 tabstop=4
#
# Load S3 transport file for a list of customer delivery destinations
# and installs a new transport maps file for postfix
#
# Copyright: Copyright (c) 2022. All rights reserved.
# Company: Sophos Limited or one of its affiliates.

import sys
sys.path.append("<%= @xgemail_utils_path %>")
import botocore
import time
import boto3
import json
import os
import subprocess
import logging
import traceback
import configformatter
import hashlib
from logging.handlers import SysLogHandler
from awshandler import AwsHandler

# Constants
POSTFIX_INSTANCE_NAME = '<%= @postfix_instance_name %>'
TRANSPORT_FILENAME = '<%= @transport_filename %>'
POLICY_BUCKET = '<%= @policy_bucket %>'
AWS_REGION = "<%= @aws_region %>"
TLS_SMTP_TRANSPORT_TAG = ' smtp_encrypt:'
CUSTOM_ROUTE_TRANSPORT_PATH = "<%= @custom_route_transport_path %>"
CUSTOM_RECIPIENT_TRANSPORT_FILE_NAME = CUSTOM_ROUTE_TRANSPORT_PATH + "customer-delivery-custom-recipient-transport.CONFIG"
CURRENT_INSTANCE_ID             =  "<%= @instance_id %>"
TRANSPORT_S3_FILE_NAME          = "<%= @transport_s3_file_name %>"
INSTANCE_LIST_PATH              = "<%= @flat_file_instance_list_path %>"
INSTANCE_LIST_FILE_NAME         =  INSTANCE_LIST_PATH + "flat-file-instance-list.CONFIG"

awshandler = AwsHandler(AWS_REGION)


# logging to syslog setup
logging.getLogger("botocore").setLevel(logging.WARNING)
logger = logging.getLogger('cd-transport-updater-cron')
logger.setLevel(logging.INFO)
handler = logging.handlers.SysLogHandler('/dev/log')
formatter = logging.Formatter(
    '[%(name)s] %(process)d %(levelname)s %(message)s'
)
handler.formatter = formatter
logger.addHandler(handler)

logger.info('flat file customer delivery transport updater cron started')
s3 = boto3.client('s3')
active_mode=False

# sort custom record so that email will prior to it domain
def sort_record_key(unsorted_dict):
    sorted_keys = unsorted_dict.keys()
    list_of_email=[]
    list_of_domain=[]
    for key in sorted_keys:
        if '@' in key:
            list_of_email.append(key)
        else:
            list_of_domain.append(key)
    return list_of_email + list_of_domain

def parse_domain_response(domain_name, destinations_json) :
  destination_json = destinations_json['delivery_destination']
  route = destination_json['destination']
  port = destination_json['port']
  type = destination_json['type']
  ret_val = domain_name + TLS_SMTP_TRANSPORT_TAG

  if type != 'MX':
    ret_val += '['

  ret_val += route

  if type != 'MX':
    ret_val += ']'

  if port != 25:
    ret_val += ":" + str(port)

  return ret_val

def custom_route_file_exist():
    if not POLICY_BUCKET:
      return False
      
    try:
      return awshandler.s3_key_exists(POLICY_BUCKET,CUSTOM_RECIPIENT_TRANSPORT_FILE_NAME)
      # custom route file found return true
    except botocore.exceptions.ClientError as e:
      trace = traceback.format_exc()
      logger.debug("Custom route file not Exist." + trace)
      return False

def s3_transport_flat_file_exist():
    if not POLICY_BUCKET:
      return False

    try:
      return awshandler.s3_key_exists(POLICY_BUCKET,TRANSPORT_S3_FILE_NAME)
      # transport file found return true
    except botocore.exceptions.ClientError as e:
      trace = traceback.format_exc()
      logger.error("transport file not Exist." + trace)
      return False

def flat_file_rollout_config_exist():
    if not POLICY_BUCKET:
      return False
    try:
      # flat file instance list file found return true
      return awshandler.s3_key_exists(POLICY_BUCKET,INSTANCE_LIST_FILE_NAME)
    except botocore.exceptions.ClientError as e:
      trace = traceback.format_exc()
      logger.debug("flat file instance list file not Exist." + trace)
      return False

def compare_transport_files(EXISTING_TRANSPORT,NEW_TRANSPORT):
    TRANSPORT_FILE_DIFF = NEW_TRANSPORT + '.diff'
    logger.info('For S3 base flat file Passive mode is on in region: {0} for instance id : {1}] and difference is written in file: {2}'.format(AWS_REGION,CURRENT_INSTANCE_ID, TRANSPORT_FILE_DIFF))
    with open(TRANSPORT_FILE_DIFF, 'w') as diff_file:
      with open(EXISTING_TRANSPORT) as file1:
        with open(NEW_TRANSPORT) as file2:
          diff= set(file1).symmetric_difference(file2)
          for line in diff:
            diff_file.write('{0}\n'.format(line))

if flat_file_rollout_config_exist():
  try:
      enable_instance_data= awshandler.download_data_from_s3(POLICY_BUCKET,INSTANCE_LIST_FILE_NAME)

      config = json.loads(enable_instance_data)
      if config and 'flat_file_enable_global' in config and config['flat_file_enable_global'] == 'true':
          active_mode=True
      else:
          if config and config['instance_id_enabled'] and CURRENT_INSTANCE_ID is not None and CURRENT_INSTANCE_ID in config['instance_id_enabled'].keys():
              logger.info('For S3 base flat file Instance id {0} exists in Config mode is on in region: {1}'.format(CURRENT_INSTANCE_ID,AWS_REGION))
              if CURRENT_INSTANCE_ID in config['instance_id_enabled'] and config['instance_id_enabled'][CURRENT_INSTANCE_ID]=='ACTIVE':
                  active_mode=True
                  logger.info('For S3 base flat file Instance id {0} exists in Config with ACTIVE mode in region: {1}'.format(CURRENT_INSTANCE_ID,AWS_REGION))
          else:
              logger.warn('Instance id {0} Not exists in file {1} will Continue the legacy '.format(CURRENT_INSTANCE_ID, INSTANCE_LIST_FILE_NAME))
              sys.exit(0)
  except Exception as e:
      logger.error("Error loading flat file rollout Instance list file " + e.message)
      sys.exit(0)
else:
    logger.info("flat file rollout Config not exist, exit from flat file cron")
    sys.exit(0)

timestamp_start=time.time() * 1000
POSTFIX_CONFIG_DIR = subprocess.check_output(
  [
    'postmulti', '-i', POSTFIX_INSTANCE_NAME, '-x',
    'postconf','-h','config_directory'
  ]
).rstrip()

TRANSPORT_FILE = POSTFIX_CONFIG_DIR + '/' + TRANSPORT_FILENAME
TRANSPORT_FILE_TMP = TRANSPORT_FILE + '.s3_flat'

logger.info('starting to update transport map file [%s.db]', TRANSPORT_FILE_TMP)

with open(TRANSPORT_FILE_TMP, 'w') as f:
    if ((POSTFIX_INSTANCE_NAME == 'postfix-cd') or (POSTFIX_INSTANCE_NAME == 'postfix-cx')  or (POSTFIX_INSTANCE_NAME == 'postfix-xd')):
        if custom_route_file_exist():
          try:
              #current_config = s3.get_object(Bucket=POLICY_BUCKET,Key= CUSTOM_RECIPIENT_TRANSPORT_FILE_NAME)
              #raw_config_data= current_config['Body'].read()
              raw_config_data= awshandler.download_data_from_s3(POLICY_BUCKET,CUSTOM_RECIPIENT_TRANSPORT_FILE_NAME)

              config_data = configformatter.get_config_binary(raw_config_data)
              record = json.loads(config_data)

              sorted_record_keys=sort_record_key(record)
              for domain_or_email in sorted_record_keys :
                  transport_line = parse_domain_response(domain_or_email,record[domain_or_email])
                  f.write('{0}\n'.format(transport_line))
          except Exception as e:
              trace = traceback.format_exc()
              for line in trace.splitlines():
                  logger.error("Error loading custom Transport " + line)

    if s3_transport_flat_file_exist():
        try:
            transport_data= awshandler.download_data_from_s3(POLICY_BUCKET,TRANSPORT_S3_FILE_NAME)
            for transport_line in transport_data.splitlines():
                f.write('{0}\n'.format(transport_line.strip()))
        except Exception as e:
            trace = traceback.format_exc()
            for line in trace.splitlines():
                logger.error("Error loading Transport " + line)
            sys.exit(0)
    else:
        logger.error("S3 Transport file not exist. Exiting from flat file cron" )
        sys.exit(0)
    if (float(round(time.time() * 1000)) - float(timestamp_start)) > 5 * 60 * 1000:
        logger.warn('transport map file updater taken more than 5 mins')

    # Add catch-all to retry any unknown domain
    f.write('* retry: domain is unknown\n')
if not active_mode:
    compare_transport_files(TRANSPORT_FILE,TRANSPORT_FILE_TMP);
if active_mode:
    subprocess.call(['postmap', 'hash:{0}'.format(TRANSPORT_FILE_TMP)])
    os.rename(TRANSPORT_FILE_TMP, TRANSPORT_FILE);
    os.rename(TRANSPORT_FILE_TMP + '.db', TRANSPORT_FILE + '.db');
    logger.info('transport map file [%s.db] successfully updated from s3 flat file. Time taken [%s]', TRANSPORT_FILE, float(round(time.time() * 1000)) - float(timestamp_start))
