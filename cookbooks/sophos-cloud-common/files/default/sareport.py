#!/usr/bin/env python
# vim: autoindent expandtab shiftwidth=4 filetype=python

# Copyright 2018, Sophos Limited. All rights reserved.
#
# 'Sophos' and 'Sophos Anti-Virus' are registered trademarks of
# Sophos Limited and Sophos Group.  All other product and company
# names mentioned are trademarks or registered trademarks of their
# respective owners.

"""
Print system activity previously recorded by sadc command.

The sadc command is installed by the sysstat package and is configured
in /etc/sysconfig/sysstat and /etc/cron.d/sysstat.  Data files are stored
in /var/log/sa/.  For more information see https://github.com/sysstat/sysstat.

IMPORTANT: sadc only evaluates the device list when it creates the daily data
file, typically at instance launch and thereafter at 00:00 UTC each day.
Therefore, if there are any disks that are attached after instance launch
(e.g. for /mongodata) then there will be no statistics recorded for them
until the next change of day.
"""

import argparse
import collections
import datetime
import json
import os
import re
import signal
import subprocess
import sys

import botocore.exceptions

import sophos.aws
import sophos.common


# TODO ;;; Provide a way to customize metrics printed.
# Can map metrics to the sadf/sar options needed to fetch them.
# Things to watch out for:
# 1. There aren't always unique mappings from metric to sar option.
#    For example, both sar -b and sar -d generate tps fields.
#    We can use an alias like "btps" do disambiguate.
# 2. Some of the metrics documented in the man page may not be available.
#    For example, the sar -u option might produce %sys or %system metrics,
#    but not both.
# 3. Some of the metrics documented in the man page are only available
#    if the collector is configured to gather them.  For example, the
#    TCP and UDP device counters are not generated by default; you
#    have to modify /etc/sysconfig/sysstat to generate them.


# The sadf command selects which data to report by passing the same options
# used by the sar command.  In our case we want these:
SAR_OPTIONS = [
    "-q",           # Report queue length and load averages.
    "-u",           # Report CPU utilization.
    "-r",           # Report memory utilization statistics.
    "-n", "SOCK",   # Report statistics from IPv4 sockets.
    "-n", "DEV",    # Report statistics from network devices.
]


# The following metrics are associated with the entire system:
# The comments for each metric provide the sar option that exposes the
# metric and the description of the metric taken from the sar man page.
SYSTEM_METRICS = [
    # -q: System load average for the past 5 minutes.
    "ldavg-5",

    # -u: Percentage  of  CPU utilization that occurred while executing at the user level (application).
    #     Note that this field includes time spent running virtual processors.
    "%user",

    # -u: Percentage of CPU utilization that occurred while executing at the system level (kernel).
    #     Note that this field includes time spent servicing hardware and software interrupts.
    "%system",

    # -u: Percentage of time that the CPU or CPUs were idle during which the system had an outstanding disk I/O request.
    "%iowait",

    # -u: Percentage of time that the CPU or CPUs were idle and the system did not have an outstanding disk I/O request.
    "%idle",

    # -r: Percentage of memory needed for current workload in relation to the total amount of memory (RAM+swap).
    "%commit",

    # -n SOCK: Number of TCP sockets currently in use.
    "tcpsck",

    # -n DEV: Total number of kilobytes received per second.
    "rxkB/s",

    # -n DEV: Total number of kilobytes transmitted per second.
    "txkB/s",

    # SYNTHESIZED: Gigabits transferred (received or transmitted) per second.
    "Gbps",
]


# The following metrics are associated with a device, typically a disk.
# These metrics are accessed using the sar -d option.  The comments for
# each metric provide the description of the metric taken from the sar
# man page.
DEVICE_METRICS = [
    # Indicate the number of transfers per second that were issued to the device.
    # Multiple logical requests can be combined into a single I/O request to the device.
    # A transfer is of indeterminate size.
    "tps",

    # The average queue length of the requests that were issued to the device.
    "avgqu-sz",

    # The average time (in milliseconds) for I/O requests issued to the device to be served.
    # This includes the time spent by the requests in queue and the time spent servicing them.
    "await",

    # The average service time (in milliseconds) for I/O requests that were issued to the device.
    "svctm",

    # Percentage of CPU time during which I/O requests were issued to the device (bandwidth
    # utilization for the device).  Device saturation occurs when this value is close to 100%.
    "%util",
]


DEFAULT_DEVICES = """
-
all
eth0
""".split()


def parse_command_line():
    doclines = __doc__.strip().splitlines()
    description = doclines[0]
    epilog = ("\n".join(doclines[1:])).strip()

    parser = argparse.ArgumentParser(
            formatter_class=argparse.RawDescriptionHelpFormatter,
            description=description,
            epilog=epilog)

    parser.add_argument(
            "-a", "--aws", action="store_true", default=False,
            help="include data about this AWS instance and its volumes")

    parser.add_argument(
            "-d", "--df", action="store_true", default=False,
            help="include data from df about disk space and inode usage")

    parser.add_argument(
            "-i", "--ignore", action="store_true", default=False,
            help="ignore non-existent paths specified by --path")

    parser.add_argument(
            "-p", "--path", metavar="PATH", action="append", dest="paths", default=[],
            help="include stats for device where PATH is found")

    parser.add_argument(
            "-n", "--ndays", metavar="NUM", type=int, default=7,
            help="report activity for last NUM days (default: %(default)s)")

    parser.add_argument(
            "-j", "--json", action="store_true", default=False,
            help="print activity data as JSON instead of raw data")

    parser.add_argument(
            "-D", "--debug", action="store_true", default=False,
            help="print extra data for debugging")

    args = parser.parse_args()

    return args


SA_DIR = "/var/log/sa"

SA_FILENAME_REGEX = r"^sa\d\d$"

def get_sa_paths(args):
    paths = []

    for filename in os.listdir(SA_DIR):
        if re.match(SA_FILENAME_REGEX, filename):
            path = os.path.join(SA_DIR, filename)
            paths.append(path)

    # Sort by ascending creation time.
    paths.sort(key=lambda path: os.stat(path).st_ctime)

    # Restrict to at most the last args.ndays files.
    paths = paths[max(0, len(paths)-args.ndays):]

    return paths


def get_mount_point(path):
    command = ["/bin/df", "--output=target", path]

    output = subprocess.check_output(command)

    lines = output.splitlines()

    path = lines[1].strip()

    return path


def get_device_paths_by_mount_point():
    device_paths_by_mount_point = dict()

    with open("/proc/mounts") as fp:
        for line in fp:
            fields = line.strip().split()
            device_path = fields[0]
            mount_point = fields[1]
            device_paths_by_mount_point[mount_point] = device_path

    return device_paths_by_mount_point


def get_mount_points_by_device_name(device_paths_by_mount_point):
    mount_points_by_device_name = dict()

    for mount_point, device_path in device_paths_by_mount_point.items():
        device_name = os.path.basename(device_path)
        mount_points_by_device_name[device_name] = mount_point

    return mount_points_by_device_name


def get_device_names(args, device_paths_by_mount_point):
    # Convert file paths to device names emitted by sadf command.

    mount_points = set()

    for path in args.paths:
        if args.ignore and not os.path.exists(path):
            continue
        mount_point = get_mount_point(path)
        mount_points.add(mount_point)

    if len(mount_points) == 0:
        return []

    device_paths = [device_paths_by_mount_point[mount_point] for mount_point in mount_points]

    device_names = [os.path.basename(device_path) for device_path in device_paths]

    return device_names


def get_sadf_command(sa_path, device_names, sar_options):
        command = ["/usr/bin/sadf", "-p"]

        if sa_path is not None:
            command.extend([sa_path])

        command.extend(["--"])
        command.extend(sar_options)

        if len(device_names) > 0:
            command.extend(["-d", "-p"])

        return command


def get_sadf_commands(sa_paths, device_names, sar_options):
    # The sadf command only accepts a single path argument so we have to generate
    # a separate command for each path.

    commands = []

    if len(sa_paths) == 0:
        command = get_sadf_command(None, device_names, sar_options)
        commands.append(command)
        return commands

    for sa_path in sa_paths:
        command = get_sadf_command(sa_path, device_names, sar_options)
        commands.append(command)

    return commands


def get_data_by_timestamp_and_device(sadf_commands, device_names, mount_points_by_device_name):
    data_by_timestamp_and_device = collections.defaultdict(lambda: collections.defaultdict(dict))

    for sadf_command in sadf_commands:
        output = subprocess.check_output(sadf_command)

        for line in output.strip().splitlines():
            # Ignore entry signifying instance launch.
            if "LINUX-RESTART" in line:
                continue

            hostname, seconds, timestamp, device, metric, value = line.strip().split()

            # Non-NVME EC2 instances show / mapped onto xvda1 but sar/sadf reports the device as xvda.
            # NVME EC2 instances show / mapped onto nvme0n1p1 but sar/sadf reports the device as nvme0n1.
            if device == "xvda":
                device = "xvda1"
            elif device == "nvme0n1":
                device = "nvme0n1p1"

            if device in DEFAULT_DEVICES:
                device = ""
            elif device not in device_names:
                continue

            mount_point = mount_points_by_device_name.get(device, device)

            data_by_timestamp_and_device[timestamp][mount_point][metric] = value

    # Synthesize Gbps (GigaBITS per second) from sum of rxkB/s and txkB/s metrics.
    # Multiply by 8 to convert bytes to bits.
    # Divide by 1024**2 to convert K to G.
    for timestamp, data_by_device in data_by_timestamp_and_device.iteritems():
        rxkB = float(data_by_device[""]["rxkB/s"])
        txkB = float(data_by_device[""]["txkB/s"])
        Gbps = (rxkB + txkB) * 8 / (1024 * 1024)
        data_by_device[""]["Gbps"] = round(Gbps, 3)

    return data_by_timestamp_and_device


def get_aws_data():
    # Find instance-id and region using ec2-metadata.
    instance_id = subprocess.check_output(["ec2-metadata", "-i"]).strip().split()[1]
    region = subprocess.check_output(["ec2-metadata", "-z"]).strip().split()[1][0:-1]

    # Use boto3 to get the rest.
    aws = sophos.aws.AwsHelper(region=region)

    response = aws.ec2_describe_instances(InstanceIds=[instance_id])
    instance = response["Reservations"][0]["Instances"][0]

    volumes = []
    try:
        for block_device_mapping in instance["BlockDeviceMappings"]:
            volume_id = block_device_mapping["Ebs"]["VolumeId"]
            response = aws.ec2_describe_volumes(VolumeIds=[volume_id])
            volume = response["Volumes"][0]
            volumes.append(volume)
    except botocore.exceptions.ClientError as e:
        # Print exception but continue
        print >> sys.stderr, e

    return {
        "instance": instance,
        "volumes": volumes
    }


def print_aws_tags(resource):
    tags = resource.get("Tags", [])

    if len(tags) == 0:
        print "tags:         ", "none"
        return

    print "tags:"
    for tag in sorted(tags, key=lambda tag: tag["Key"]):
        print "- %s: %s" % (tag["Key"], tag["Value"])


def print_aws(aws_data):
    instance = aws_data["instance"]

    print
    print "instance-id:  ", instance["InstanceId"]
    print "instance-type:", instance["InstanceType"]
    print "ebs-optimized:", str(instance["EbsOptimized"]).lower()
    print "launch-time:  ", instance["LaunchTime"].strftime("%Y-%m-%dT%H:%M:%S")
    print "placement:    ", instance["Placement"]["AvailabilityZone"]
    print "private-ip:   ", instance.get("PrivateIpAddress", "none")
    print "public-ip:    ", instance.get("PublicIpAddress", "none")
    print "subnet-id:    ", instance.get("SubnetId", "none")
    print "vpc-id:       ", instance.get("VpcId", "none")
    print_aws_tags(instance)

    for volume in aws_data["volumes"]:
        print
        print "volume-id:    ", volume["VolumeId"]
        print "volume-type:  ", volume["VolumeType"]
        print "size:         ", volume["Size"]
        print "iops:         ", volume.get("Iops", "none")
        print "create-time:  ", volume["CreateTime"].strftime("%Y-%m-%dT%H:%M:%S")
        print "encrypted:    ", str(volume["Encrypted"]).lower()
        print "device:       ", volume["Attachments"][0]["Device"]
        print "ephemeral:    ", str(volume["Attachments"][0]["DeleteOnTermination"]).lower()
        print_aws_tags(volume)


def get_df_data():
    # If you don't elaborate on the --output option you get all the fields.
    df_output = subprocess.check_output(["df", "--output"])
    lines = df_output.splitlines()

    # Use column headings as keys for the dicts we will return.
    keys = lines.pop(0).strip().split()

    df_data = []
    for line in lines:
        values = line.strip().split()
        df_data.append({ keys[i]: values[i] for i in range(len(values)) })

    return df_data


def print_df(df_data):
    for d in df_data:
        print
        print "Filesystem: ", d["Filesystem"]
        print "Type:       ", d["Type"]
        print "Inodes:     ", d["Inodes"]
        print "IUsed:      ", d["IUsed"]
        print "IUse%:      ", d["IUse%"]
        print "1K-blocks:  ", d["1K-blocks"]
        print "Used:       ", d["Used"]
        print "Use%:       ", d["Use%"]
        print "Mounted:    ", d["Mounted"]


def print_json(obj):
    print json.dumps(obj, default=str, indent=4, sort_keys=True)


def get_timestamp_str(timestamp):
    return str(datetime.datetime.fromtimestamp(float(timestamp))).replace(" ", "T")


def get_stats_by_timestamp_and_device(data_by_timestamp_and_device):
    stat_accumulators_by_device_and_metric = collections.defaultdict(lambda: collections.defaultdict(lambda: sophos.common.StatsAccumulator(True)))

    for data_by_device in data_by_timestamp_and_device.values():
        for device, data in data_by_device.items():
            for metric, value in data.items():
                stat_accumulators_by_device_and_metric[device][metric].add(value)

    stats_by_device_and_metric = collections.defaultdict(lambda: collections.defaultdict(lambda: collections.defaultdict()))

    for device, stat_accumulators_by_metric in sorted(stat_accumulators_by_device_and_metric.items()):
        if device == "":
            metrics = SYSTEM_METRICS
        else:
            metrics = DEVICE_METRICS

        for metric in metrics:
            stats_accumulator = stat_accumulators_by_metric[metric]

            stats = stats_by_device_and_metric[device][metric]
            stats["mean"] = stats_accumulator.mean()
            stats["stddev"] = stats_accumulator.stddev()
            stats["num"] = stats_accumulator.num()
            stats["min"] = stats_accumulator.min()
            stats["p25"] = stats_accumulator.percentile(25)
            stats["p50"] = stats_accumulator.percentile(50)
            stats["p75"] = stats_accumulator.percentile(75)
            stats["p95"] = stats_accumulator.percentile(95)
            stats["max"] = stats_accumulator.max()

    return stats_by_device_and_metric


def print_stats(data_by_timestamp_and_device, stats_by_device_and_metric):
    timestamps = map(int, data_by_timestamp_and_device.keys())

    print
    print "From:", get_timestamp_str(min(timestamps))
    print "To:  ", get_timestamp_str(max(timestamps))

    rows = [
        [ "metric", "device", "mean", "stddev", "samples", "min", "p25", "median", "p75", "p95", "max" ],
        "-"
    ]

    for device, stats_by_metric in sorted(stats_by_device_and_metric.items()):
        if device == "":
            metrics = SYSTEM_METRICS
        else:
            metrics = DEVICE_METRICS

        rows.append(None)

        for metric in metrics:
            stats = stats_by_metric[metric]
            row = [
                metric,
                device,
                round(stats["mean"], 3),
                round(stats["stddev"], 3),
                stats["num"],
                round(stats["min"], 3),
                round(stats["p25"], 3),
                round(stats["p50"], 3),
                round(stats["p75"], 3),
                round(stats["p95"], 3),
                round(stats["max"], 3),
            ]
            rows.append(row)

    print
    sophos.common.print_rows(rows)
    print


# Re-print header after this many entries.
# Choose a multiple of 6 since the default data collection
# frequency is every 10 minutes, i.e. 6 times per hour.
MAX_ENTRIES_BEFORE_HEADER = 6

def floatify(value):
    try:
        return float(value)
    except Exception:
        return value

def print_data(data_by_timestamp_and_device):
    rows = []

    prev_hour = None
    for timestamp in sorted(data_by_timestamp_and_device.keys()):
        data_by_device = data_by_timestamp_and_device[timestamp]

        timestamp_str = get_timestamp_str(timestamp)

        curr_hour = timestamp_str.split(":")[0]
        header_needed = curr_hour != prev_hour
        prev_hour = curr_hour

        non_device_data = data_by_device[""]
        non_device_fields = map(floatify, [non_device_data.get(metric, "-") for metric in SYSTEM_METRICS])
        non_device_placeholders = ["-"] * len(non_device_fields)

        devices = sorted([key for key in data_by_device.keys() if key != ""])

        if header_needed:
            header = [ "timestamp" ] + SYSTEM_METRICS
            if len(devices) > 0:
                header.extend(DEVICE_METRICS)
                header.append("device")

            rows.append(None)
            rows.append(header)

        row = [ timestamp_str ] + non_device_fields

        if len(devices) == 0:
            rows.append(row)
            continue

        for i, device in enumerate(devices):
            device_data = data_by_device[device]
            device_fields = map(floatify, [device_data.get(metric, "-") for metric in DEVICE_METRICS])
            row.extend(device_fields)
            row.append(device)
            rows.append(row)
            row = [ "" ] * (1 + len(SYSTEM_METRICS))

    print
    sophos.common.print_rows(rows)
    print


def debug_print(args, label, obj):
    if args.debug:
        print
        print "%s:" % label
        print_json(obj)


def main():
    args = parse_command_line()

    sa_paths = get_sa_paths(args)
    debug_print(args, "sa_paths", sa_paths)

    device_paths_by_mount_point = get_device_paths_by_mount_point()
    debug_print(args, "device_paths_by_mount_point", device_paths_by_mount_point)

    mount_points_by_device_name = get_mount_points_by_device_name(device_paths_by_mount_point)
    debug_print(args, "mount_points_by_device_name", mount_points_by_device_name)

    device_names = get_device_names(args, device_paths_by_mount_point)
    debug_print(args, "device_names", device_names)

    sadf_commands = get_sadf_commands(sa_paths, device_names, SAR_OPTIONS)
    debug_print(args, "sadf_commands", sadf_commands)

    # Get the data.

    aws_data = None
    if args.aws:
        aws_data = get_aws_data()

    df_data = None
    if args.df:
        df_data = get_df_data()

    data_by_timestamp_and_device = get_data_by_timestamp_and_device(sadf_commands, device_names, mount_points_by_device_name)

    stats_by_device_and_metric = get_stats_by_timestamp_and_device(data_by_timestamp_and_device)

    # Print it.

    if args.json:
        print_json({
            "aws": aws_data,
            "df": df_data,
            "data": data_by_timestamp_and_device,
            "stats": stats_by_device_and_metric
        })
    else:
        if aws_data is not None:
            print_aws(aws_data)
        if df_data is not None:
            print_df(df_data)
        print_data(data_by_timestamp_and_device)
        print_stats(data_by_timestamp_and_device, stats_by_device_and_metric)

    return 0


if __name__ == "__main__":
    signal.signal(signal.SIGPIPE, signal.SIG_DFL)
    try:
        sys.exit(main())
    except KeyboardInterrupt:
        sys.exit(128 + signal.SIGINT)
